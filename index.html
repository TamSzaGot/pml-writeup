<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="pml-writeup : Coursera, Practical Machine Learning - December 2014, Writeup">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>pml-writeup</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
<!--      <a id="forkme_banner" href="https://github.com/TamSzaGot/pml-writeup">View on GitHub</a>  -->

          <h1 id="project_title">pml-writeup</h1>
          <h2 id="project_tagline">Coursera, Practical Machine Learning - December 2014, Writeup</h2>

<!--             <section id="downloads">
              <a class="zip_download_link" href="https://github.com/TamSzaGot/pml-writeup/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/TamSzaGot/pml-writeup/tarball/master">Download this project as a tar.gz file</a>
            </section> -->
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="pml-writeup" class="anchor" href="#pml-writeup" aria-hidden="true"><span class="octicon octicon-link"></span></a>pml-writeup</h1>

<p>Coursera, Practical Machine Learning - December 2014, Writeup</p>
<h2>Background</h2>
<p>This is a Prediction Assignment Writeup for the Coursera course Practical Machine Learning, December 2014. The Goal is to build a model that can be used to identify correct or incorrect ways to do exercise based on body sensor data. The data being used comes from the <a href="http://groupware.les.inf.puc-rio.br/har">Human Activity Recognition</a> Weight Lifting Exercises Dataset where output from differens body sensors have been collected.</p> 
<p>The original sensor data has been split into a training data set and test data set for this assignment and have been made available for download as pml-training.csv and pml-testing.csv files.</p>
<p>There were six persons participating in the collection of the sensor data and while doing barbell lifts in five different ways. The way they did the exercise was categorized and noted in the "classe" variable. So this is the variable the model being built has to predict.</p>
<h2>Initial Data Analysis</h2>
<p>The training and test data sets were downloaded to local storage and read into variables. The training set being quite large containing 19622 rows with 160 variables, and some of them having empty or NA values. </p>
<pre>
&gt; setwd("/home/tamas/workspace/testR")
&gt; training &lt;- read.csv("data/pml-training.csv",TRUE,",")
&gt; testing &lt;- read.csv("data/pml-testing.csv",TRUE,",")
&gt; dim(training)
[1] 19622   160
&gt; dim(testing)
[1]  20 160
&gt; head(training)
  X user_name raw_timestamp_part_1 raw_timestamp_part_2   cvtd_timestamp
1 1  carlitos           1323084231               788290 05/12/2011 11:23
2 2  carlitos           1323084231               808298 05/12/2011 11:23
3 3  carlitos           1323084231               820366 05/12/2011 11:23
...
  skewness_roll_belt.1 skewness_yaw_belt max_roll_belt max_picth_belt
1                                                   NA             NA
2                                                   NA             NA
3                                                   NA             NA
...
</pre>
<p>In an effort to visualize what the data look like when the different classes of exercises were made by the different test persons, a couple of functions were defined so that variables could be plotted against time</p>
<pre>
getData <- function(dataset, name) {
	s <- dataset[dataset$user_name %in% c(name),]
	return(s)
}

getTime <- function(subdata) {
	t0 <- min(subdata$raw_timestamp_part_1)
	t <- (subdata$raw_timestamp_part_1 - t0) * 2^20 +
          subdata$raw_timestamp_part_2
	return(t)
}

plotData <- function(name, sensor, dataset = training) {
	subdata <- getData(dataset, name)
	time <- getTime(subdata)
	family <- as.factor(subdata$classe)
	y <- subdata[[sensor]]
	plot(time, y, pch=19, col=family, main=paste(sensor, name, " "))
}

plotAll <- function(sensor) {
	par(mfrow=c(2,3))
	plotData("adelmo", sensor)
	plotData("carlitos", sensor)
	plotData("pedro", sensor)
	plotData("charles", sensor)
	plotData("jeremy", sensor)
	plotData("eurico", sensor)
}
</pre>
<p>With the plotAll function different sensors could be examined. Like the sensor variable "accel_forearm_x" for instance.</p>
<pre>
&gt; png("accel_forearm_x.png",width = 640, height = 640, pointsize = 18)
&gt; plotAll("accel_forearm_x")
&gt; dev.off()
</pre>
<img src="images/accel_forearm_x.png"/>
<p>While studying the plots for different sensors a couple of things could be observed.</p>
<ul>
<li>For one single class of exercise the sensor output span a broad range of values, since the whole amplitude of the barbell lifts are being detected.</li>
<li>The sensor values differ more between persons than between different classes</li>
<li>There might be some misclassification of the data. Compare for instance exercise class "D" (blue) between adelmo, charles and jeremy. It looks like the data for class "D" in fact is situated between the two shades of blue for adelmo and charles, and hence misclassified in the dataset. Similar potential misclassifications can be observed for other sensor variables.</li>
</ul>
<p>This leads to the conclusion that as many as possible of the sensor variables should be used to be able to find a proper model. Since the Random Forest method can handle many variables while doing classification it was chosen for the model creation.
<h2>Model Creation</h2>
<p>To be able to create a Random Forests model the NA values has to be removed from the training data. But it turned out not to be enough as some of the variables in the training set are Factor types with to many levels for the Random Forest train functions to manage. Furthermore, some of the variables, like "X", "user_name", "raw_timestamp_part_1" etc are irrelevant for the identification, so eventually except the sought variable "classe" only the sensor variables with proper data were selected.</p>
<pre>
&gt; training1 &lt;- training[,colSums(is.na(training)) &lt; 1]
&gt; x &lt;- training1[,c("roll_belt", "pitch_belt", "yaw_belt",
            "roll_arm", "pitch_arm", "yaw_arm",
            "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell",
            "roll_forearm", "pitch_forearm", "yaw_forearm",
            "gyros_belt_x", "gyros_belt_y", "gyros_belt_z",
            "accel_belt_x", "accel_belt_y", "accel_belt_z",
            "magnet_belt_x", "magnet_belt_y", "magnet_belt_z",
            "gyros_arm_x", "gyros_arm_y", "gyros_arm_z",
            "accel_arm_x", "accel_arm_y", "accel_arm_z",
            "magnet_arm_x", "magnet_arm_y", "magnet_arm_z",
            "gyros_dumbbell_x", "gyros_dumbbell_y", "gyros_dumbbell_z",
            "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z",
            "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z",
            "gyros_forearm_x", "gyros_forearm_y", "gyros_forearm_z",
            "accel_forearm_x", "accel_forearm_y", "accel_forearm_z",
            "magnet_forearm_x", "magnet_forearm_y", "magnet_forearm_z",
            "classe")]
</pre>
<p>Since the run time when doing Random Forest computations can be quite long with large data sets, the data were sampled to get a subset of the data to start with. Before using the <b>train</b> function from the <b>caret</b> library an attempt to use the <b>randomForest</b> function directly were made. This function can be faster since it doesn't do any implicit extra calculations like out of bag cross validation.</p>
<pre>
&gt; library(randomForest)
&gt; x1 &lt;- x[sample(nrow(x), 500),]
&gt; set.seed(331)
&gt; fit.rf &lt;- randomForest(classe ~ ., data=x1)
&gt; print(fit.rf)

Call:
 randomForest(formula = classe ~ ., data = x1) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 6

        OOB estimate of  error rate: 14.2%
Confusion matrix:
    A  B  C  D  E class.error
A 142  0  2  5  0  0.04697987
B  11 55  9  4  6  0.35294118
C   3  4 80  2  0  0.10112360
D   2  1  7 64  3  0.16883117
E   2  2  6  2 88  0.12000000
</pre>
<p>A 14 percent error rate with just 500 samples, not bad considering what the data look like! Now increase the sample size to 5000 and see if the error rate decreases.</p>
<pre>
&gt; set.seed(331)
&gt; x1 &lt;- x[sample(nrow(x), 5000),]
&gt; fit.rf &lt;- randomForest(classe ~ ., data=x1)
&gt; print(fit.rf)

Call:
 randomForest(formula = classe ~ ., data = x1) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 6

        OOB estimate of  error rate: 2.14%
Confusion matrix:
     A   B   C   D   E class.error
A 1446   6   2   1   0 0.006185567
B   22 943  11   0   0 0.033811475
C    1  27 818   3   0 0.036513545
D    1   0  25 773   2 0.034956305
E    0   0   1   5 913 0.006528836
</pre>
<p>It does. The out of band estimation of the error rate is just 2 percent. What about variable importance? Can some of the variables be dropped to keep computation times down? The variable importance can be extracted and plotted as follows.</p>

<pre>
&gt; imp1 &lt;- data.frame(importance(fit.rf))
&gt; attach(imp1)
&gt; imp2 &lt;- imp1[order(-MeanDecreaseGini), , drop=FALSE]
&gt; detach(imp1)
&gt; head(imp2)
                  MeanDecreaseGini
roll_belt                 312.9281
yaw_belt                  206.2780
pitch_forearm             192.0426
magnet_dumbbell_z         188.9785
magnet_dumbbell_y         165.1653
pitch_belt                164.0823

&gt; png("importance500.png",width = 640, height = 640, pointsize = 18)
&gt; ploty &lt;-  as.vector(imp2$MeanDecreaseGini)
&gt; plot(ploty, main="Variable importance", xlab="variable", ylab="importance", pch=19)
&gt; text(ploty, row.names(imp2[1]), cex=0.8, pos=4, xpd=TRUE, srt=80)
&gt; dev.off()
</pre>
<img src="images/importance500.png"/>
<p>Even if there are 5-6 variables which appears to be more important then the others, the decrease in importance is quite slow. But to try to get faster computation times when more samples are being used only the 15 most important variables are picked.</p>
<pre>
&gt; x &lt;- training1[,c("roll_belt", "pitch_belt", "yaw_belt",
       "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z",
	   "pitch_forearm", "roll_forearm",
	   "magnet_belt_y", "magnet_belt_z",
	   "accel_dumbbell_y", "accel_dumbbell_z",
	   "roll_dumbbell", "accel_belt_z", "gyros_belt_z",
	   "classe")]
</pre>
<p>By using this reduced set of variables how much out of bag accuracy have we lost? Make a new computation with the reduced set of variables.</p>
<pre>
&gt; set.seed(331)
&gt; x1 &lt;- x[sample(nrow(x), 5000),]
&gt; fit.rf &lt;- randomForest(classe ~ ., data=x1)
&gt; print(fit.rf)

Call:
 randomForest(formula = classe ~ ., data = x1) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 3

        OOB estimate of  error rate: 3.3%
Confusion matrix:
     A   B   C   D   E class.error
A 1428  17   7   2   1  0.01855670
B   28 911  23  13   1  0.06659836
C    2  22 810  15   0  0.04593640
D    5   2  14 778   2  0.02871411
E    0   2   3   6 908  0.01196953
</pre>
<p>The estimated error rate increased as expected. Now take a look at the plot from the model describing de estimated error rates with respect to the number of trees in the forest.</p>
<pre>
png("trees5000_15.png",width = 640, height = 640, pointsize = 18)
plot(fit.rf)
dev.off()
</pre>
<img src="images/trees5000_15.png"/>
<p>The plot show a knee at 50 trees. After that the model only improves slightly by using more trees. By only using 50 trees the computation time can be reduced so that more samples can be used in an attempt to reduce the error rate.</p>
<h2>Model Validation</h2>
<p>With this reduced set of variables split the traning data into one set for training and one for validation of the obtained model. Set the number of trees to 50 to start with.</p>
<pre>
&gt; trainSampl &lt;- sample(nrow(x), 0.80 * dim(x)[1] )
&gt; x1 &lt;- x[trainSampl,]
&gt; v1 &lt;- x[-trainSampl,]
&gt; fit.rf &lt;- randomForest(classe ~ ., data=x1, ntree = 50)
&gt; print(fit.rf)

Call:
 randomForest(formula = classe ~ ., data = x1, ntree = 50) 
               Type of random forest: classification
                     Number of trees: 50
No. of variables tried at each split: 3

        OOB estimate of  error rate: 1.47%
Confusion matrix:
     A    B    C    D    E class.error
A 4400   17    7    5    1 0.006772009
B   27 2974   28   13    0 0.022353715
C    4   32 2662   23    0 0.021683205
D    1    4   41 2550    4 0.019230769
E    1    5    5   12 2881 0.007920110
</pre>
<p>Not too bad. Now let us use the model and do a prediction of the "classe" variable using the validation data and see how good the model are at predicting.</p>
<pre>
&gt; val1 &lt;- predict(fit.rf,v1)
&gt; table(val1,v1$classe)
    
val1    A    B    C    D    E
   A 1144    6    1    0    0
   B    4  734    4    0    1
   C    2   11  690    4    1
   D    0    4    6  612    1
   E    0    0    0    0  700
</pre>
<p>Very good, and the model can still be improoved by using more variables and growing the forest larger.</p>
<p>Now try to use the train function from the caret package to fit a Random Forest model. Are the results comparable?</p>
<pre>
&gt; library(caret)
&gt; set.seed(331)
&gt; tc &lt;- trainControl(method="cv", number=2)
&gt; fit.rf &lt;- train(classe ~., data=x1, method="rf", trControl=tc, ntree=50)
&gt; print(fit.rf)
Random Forest 

15697 samples
   15 predictors
    5 classes: 'A', 'B', 'C', 'D', 'E' 

No pre-processing
Resampling: Cross-Validated (2 fold) 

Summary of sample sizes: 7848, 7849 

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD   Kappa SD    
   2    0.9746449  0.9679496  0.0019797949  0.0024920589
   8    0.9752819  0.9687570  0.0008987182  0.0011228587
  15    0.9708861  0.9632016  0.0006332846  0.0008190101

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 8. 

&gt; confusionMatrix(fit.rf)
Cross-Validated (2 fold) Confusion Matrix 

(entries are percentages of table totals)
 
          Reference
Prediction    A    B    C    D    E
         A 27.8  0.4  0.0  0.0  0.0
         B  0.2 18.5  0.2  0.1  0.1
         C  0.1  0.3 16.9  0.3  0.1
         D  0.0  0.2  0.2 16.1  0.1
         E  0.0  0.0  0.0  0.1 18.2

&gt; val1 &lt;- predict(fit.rf,v1)
&gt; table(val1,v1$classe)
    
val1    A    B    C    D    E
   A 1144   10    1    0    0
   B    4  731    2    2    2
   C    2   13  691    6    2
   D    0    1    7  608    0
   E    0    0    0    0  699

</pre>
<p>The two packages produces comparable results.</p>
<h2>Testing</h2>
<p>Even if the models could be improved by using more variables or buildning more trees, the current model was able to make a correct prediction of the "classe" variable from the test set.</p>
<pre>
&gt; testing &lt;- read.csv("data/pml-testing.csv",TRUE,",")
&gt; pred1 &lt;- predict(fit.rf,testing)
&gt; as.vector(pred1)

 [1] "B" "A" "B" "A" "A" "E" "D" "B" "A" "A" "B" "C" "B" "A" "E" "E" "A" "B" "B"
[20] "B"
</pre>
<p>The results were submitted by uploading the created result files following the instructions and were graded all correct.</p>
<p/>
<p> Great success!</p>
<P/>
<p>Out of curiosity how much the model could be improved the data to use for training were reverted to use all (48) relevant sensor variables and to create a Random Forest model with all the available traning samples (80 percent traning and 20 percent validation) and 150 trees. This improved the error rate to 0.5 percent and the prediction rate was quite good.</p>
<pre>
&gt; val1 &lt;- predict(fit.rf,v1)
&gt; table(val1,v1$classe)
    
val1    A    B    C    D    E
   A 1091    3    0    0    0
   B    0  741    6    0    0
   C    0    0  672    2    0
   D    0    0    1  648    0
   E    1    0    0    0  760
</pre>
<P/>
<P/>
<p>Tamas Szabo<br/>
Vall, Gotland<br/>
19 December 2014</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">pml-writeup maintained by <a href="https://github.com/TamSzaGot">TamSzaGot</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
